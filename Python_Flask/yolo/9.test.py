import cv2
import time
from ultralytics import YOLO
import numpy as np
import torch

# è‡ªå‹•é¸æ“‡è¨­å‚™ï¼ˆCUDA æˆ– CPUï¼‰
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ä½¿ç”¨è¨­å‚™ï¼š{device}")

# å½±åƒä¾†æºï¼šæ”åƒé ­æˆ–å½±ç‰‡æª”æ¡ˆ 0 è¡¨ç¤ºä½¿ç”¨æ”åƒé ­
#video_source = r"D:\ç´…æ¨“åƒåœ¾\FOOT2\4.mp4"
#video_source = r"D:\ç´…æ¨“åƒåœ¾\å½±äºŒ\767690873.518051.mp4"
#video_source = r"C:\Users\james\OneDrive\æ¡Œé¢\è…³\766993860.828273.mp4"
video_source = r"D:\åœ–\foot\FOOT3\99.mp4"
cap = cv2.VideoCapture(video_source)

# æª¢æŸ¥æ˜¯å¦æˆåŠŸæ‰“é–‹å½±ç‰‡
if not cap.isOpened():
    print("âŒ ç„¡æ³•æ‰“é–‹å½±ç‰‡æˆ–æ”åƒé ­")
    exit()

# å–å¾—å½±ç‰‡FPS
fps_video = cap.get(cv2.CAP_PROP_FPS)
print(f"å½±ç‰‡åŸå§‹FPSï¼š{fps_video}")

# è¨ˆç®—æ¯ä¸€å¹€çš„ç†è«–é–“éš”æ™‚é–“
frame_interval = 1 / fps_video

# æ¨¡å‹è·¯å¾‘åŠè¼‰å…¥
model_path = r"Z:\å°ˆé¡Œ\datatest\train7\weights\best.pt"

class_names = ['X', 'O']
model = YOLO(model_path)

# åˆå§‹åŒ–è¨ˆæ•¸
prev_time = time.time()
frame_count = 0
total_fps = 0  # ç”¨æ–¼è¨ˆç®—å¹³å‡FPS

def get_color(class_name):
    """æ ¹æ“šé¡åˆ¥åç¨±è¿”å›ä¸åŒçš„é¡è‰²"""
    color_dict = {'user': (0, 255, 0), 'nouser': (0, 0, 255)}
    return color_dict.get(class_name, (0, 255, 255))

while True:
    start_time = time.time()

    ret, frame = cap.read()
    if not ret:
        print("âŒ ç„¡æ³•è®€å–å½±åƒæˆ–å½±ç‰‡çµæŸ")

        break

    # YOLOv8 é€²è¡Œåµæ¸¬
    results = model(frame, iou=0.3, conf=0.5, device=device)
    result = results[0]
    bboxes = np.array(result.boxes.xyxy.cpu(), dtype="int")
    classes = np.array(result.boxes.cls.cpu(), dtype="int")
    confs = results[0].boxes.conf.cpu().tolist()

    # ç¹ªè£½é‚Šæ¡†å’Œæ¨™è¨»
    for cls, bbox, conf in zip(classes, bboxes, confs):
        (x, y, x2, y2) = bbox
        class_name = class_names[cls]
        color = get_color(class_name)

        # ç•«æ¡†å’Œæ¨™è¨»
        cv2.rectangle(frame, (x, y), (x2, y2), color, 2)
        cv2.putText(frame, f"{class_name} ({conf:.2f})", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # è¨ˆç®—å¯¦éš› FPS
    current_time = time.time()
    actual_fps = 1 / (current_time - prev_time)
    prev_time = current_time

    # æ›´æ–°å¹€æ•¸å’Œç´¯ç©FPS
    frame_count += 1
    total_fps += actual_fps

    # é¡¯ç¤º FPS
    cv2.putText(frame, f"FPS: {actual_fps:.2f}", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # é¡¯ç¤ºå½±åƒ
    cv2.imshow("YOLOv11 Detection", frame)

    # è¨ˆç®—è™•ç†æ™‚é–“
    processing_time = time.time() - start_time

    # æ ¹æ“šåŸå§‹ FPS å’Œè™•ç†æ™‚é–“ä¾†åŒæ­¥æ’­æ”¾é€Ÿåº¦
    delay = max(int((frame_interval - processing_time) * 1000), 1)
    key = cv2.waitKey(delay)
    if key == 27:  # æŒ‰ ESC éµé€€å‡º
        break

# è¨ˆç®—å¹³å‡FPSï¼ˆå¦‚æœæœ‰è‡³å°‘ä¸€å€‹å¹€ï¼‰
if frame_count > 0:
    average_fps = total_fps / frame_count
    print(f"å½±ç‰‡åŸå§‹FPSï¼š{fps_video}")
    print(f"ä½¿ç”¨è¨­å‚™ï¼š{device}")
    print(f"\nğŸ“Š çµæŸç¨‹å¼ï¼Œç¸½å¹€æ•¸ï¼š{frame_count}ï¼Œå¹³å‡ FPSï¼š{average_fps:.2f}")
else:
    print("âš ï¸ ç„¡æ³•è¨ˆç®—å¹³å‡FPSï¼Œå› ç‚ºæ²’æœ‰è™•ç†ä»»ä½•å¹€æ•¸")

# é‡‹æ”¾è³‡æº
cap.release()
cv2.destroyAllWindows()
